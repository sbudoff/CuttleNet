{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6abec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr, pickle, csv, re, os, tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e1999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dependencies\n",
    "path = '/home/sam/scRNAseq/Xenium/Network_genes_NoiseInjection.RData'\n",
    "model_path = \"/home/sam/scRNAseq/Xenium/AlonNN/NoiseInj/model_state_epochs_150_earlyStop_50_l1_0.0001_depth_5_withSkips_seed_18.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d683d6c",
   "metadata": {},
   "source": [
    "# Model Loading And Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26920f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kcnip4</th>\n",
       "      <th>Isl2</th>\n",
       "      <th>Glra1</th>\n",
       "      <th>Zic1</th>\n",
       "      <th>Syndig1l</th>\n",
       "      <th>Isl1</th>\n",
       "      <th>Pou3f1</th>\n",
       "      <th>Mmp9</th>\n",
       "      <th>Grm5</th>\n",
       "      <th>Cpne4</th>\n",
       "      <th>...</th>\n",
       "      <th>Glrb</th>\n",
       "      <th>Rbpms</th>\n",
       "      <th>Vamp1</th>\n",
       "      <th>Cspg4</th>\n",
       "      <th>Kcnq1ot1</th>\n",
       "      <th>Cdh5</th>\n",
       "      <th>Foxp1</th>\n",
       "      <th>cluster</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aRGC4_AGCGTATGTAGCCTAT.1</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25_Novel</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aRGC3_GACTACAAGTGCGTGA.1</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.019</td>\n",
       "      <td>01_W3D1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aRGC4_GTACGTATCGCGTAGC.1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10_Novel</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aRGC4_GTACGTATCTGTCTCG.1</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>32_F_Novel</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aRGC4_GTACTCCAGATTACCC.1</th>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>04_FminiOFF</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0Endothelial</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0Endothelial</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0Endothelial</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0Pericyte</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0Microglia</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96800 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Kcnip4   Isl2  Glra1   Zic1  Syndig1l   Isl1  \\\n",
       "rownames                                                                 \n",
       "aRGC4_AGCGTATGTAGCCTAT.1   0.250  0.000  0.000  0.021     0.100  0.045   \n",
       "aRGC3_GACTACAAGTGCGTGA.1   0.250  0.000  0.048  0.000     0.025  0.000   \n",
       "aRGC4_GTACGTATCGCGTAGC.1   0.125  0.000  0.000  0.021     0.075  0.091   \n",
       "aRGC4_GTACGTATCTGTCTCG.1   0.062  0.111  0.048  0.000     0.000  0.091   \n",
       "aRGC4_GTACTCCAGATTACCC.1   0.312  0.000  0.000  0.021     0.000  0.136   \n",
       "...                          ...    ...    ...    ...       ...    ...   \n",
       "4951                       0.000  0.000  0.000  0.021     0.000  0.000   \n",
       "4941                       0.062  0.000  0.000  0.021     0.000  0.045   \n",
       "4931                       0.000  0.056  0.000  0.000     0.000  0.000   \n",
       "2102                       0.000  0.000  0.000  0.000     0.000  0.045   \n",
       "267                        0.062  0.056  0.000  0.000     0.000  0.000   \n",
       "\n",
       "                          Pou3f1   Mmp9   Grm5  Cpne4  ...   Glrb  Rbpms  \\\n",
       "rownames                                               ...                 \n",
       "aRGC4_AGCGTATGTAGCCTAT.1     0.0  0.000  0.000  0.000  ...  0.032  0.108   \n",
       "aRGC3_GACTACAAGTGCGTGA.1     0.0  0.099  0.077  0.048  ...  0.000  0.162   \n",
       "aRGC4_GTACGTATCGCGTAGC.1     0.0  0.155  0.154  0.048  ...  0.159  0.135   \n",
       "aRGC4_GTACGTATCTGTCTCG.1     0.0  0.000  0.000  0.000  ...  0.111  0.000   \n",
       "aRGC4_GTACTCCAGATTACCC.1     0.0  0.014  0.000  0.143  ...  0.127  0.270   \n",
       "...                          ...    ...    ...    ...  ...    ...    ...   \n",
       "4951                         0.0  0.000  0.000  0.000  ...  0.032  0.000   \n",
       "4941                         0.0  0.000  0.077  0.000  ...  0.000  0.000   \n",
       "4931                         0.0  0.014  0.077  0.000  ...  0.048  0.000   \n",
       "2102                         0.0  0.000  0.000  0.000  ...  0.048  0.000   \n",
       "267                          0.0  0.000  0.000  0.048  ...  0.048  0.000   \n",
       "\n",
       "                          Vamp1  Cspg4  Kcnq1ot1   Cdh5  Foxp1       cluster  \\\n",
       "rownames                                                                       \n",
       "aRGC4_AGCGTATGTAGCCTAT.1  0.114   0.05     0.167  0.000  0.000      25_Novel   \n",
       "aRGC3_GACTACAAGTGCGTGA.1  0.000   0.00     0.083  0.167  0.019     01_W3D1.1   \n",
       "aRGC4_GTACGTATCGCGTAGC.1  0.025   0.00     0.167  0.000  0.000      10_Novel   \n",
       "aRGC4_GTACGTATCTGTCTCG.1  0.051   0.00     0.000  0.000  0.056    32_F_Novel   \n",
       "aRGC4_GTACTCCAGATTACCC.1  0.228   0.00     0.000  0.000  0.259   04_FminiOFF   \n",
       "...                         ...    ...       ...    ...    ...           ...   \n",
       "4951                      0.000   0.05     0.000  0.167  0.000  0Endothelial   \n",
       "4941                      0.013   0.00     0.000  0.333  0.000  0Endothelial   \n",
       "4931                      0.038   0.05     0.000  0.333  0.000  0Endothelial   \n",
       "2102                      0.000   0.45     0.000  0.000  0.000     0Pericyte   \n",
       "267                       0.000   0.00     0.000  0.000  0.000    0Microglia   \n",
       "\n",
       "                          Cluster  Class  \n",
       "rownames                                  \n",
       "aRGC4_AGCGTATGTAGCCTAT.1       45      0  \n",
       "aRGC3_GACTACAAGTGCGTGA.1        0      0  \n",
       "aRGC4_GTACGTATCGCGTAGC.1       30      0  \n",
       "aRGC4_GTACGTATCTGTCTCG.1       52      0  \n",
       "aRGC4_GTACTCCAGATTACCC.1        3      0  \n",
       "...                           ...    ...  \n",
       "4951                           23      6  \n",
       "4941                           23      6  \n",
       "4931                           23      6  \n",
       "2102                           27      6  \n",
       "267                            26      6  \n",
       "\n",
       "[96800 rows x 303 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{45: 0, 0: 0, 30: 0, 52: 0, 3: 0, 4: 0, 2: 0, 33: 0, 36: 0, 5: 0, 61: 0, 6: 0, 46: 0, 48: 0, 8: 0, 38: 0, 35: 0, 51: 0, 37: 0, 47: 0, 34: 0, 49: 0, 31: 0, 1: 0, 32: 0, 40: 0, 39: 0, 55: 0, 7: 0, 43: 0, 50: 0, 41: 0, 62: 0, 54: 0, 57: 0, 56: 0, 42: 0, 44: 0, 58: 0, 60: 0, 53: 0, 59: 0, 65: 0, 63: 0, 64: 0, 126: 1, 100: 1, 66: 1, 67: 1, 88: 1, 77: 1, 127: 1, 76: 1, 70: 1, 72: 1, 99: 1, 89: 1, 121: 1, 74: 1, 102: 1, 110: 1, 94: 1, 93: 1, 96: 1, 83: 1, 95: 1, 92: 1, 68: 1, 86: 1, 69: 1, 82: 1, 75: 1, 80: 1, 91: 1, 78: 1, 113: 1, 87: 1, 105: 1, 71: 1, 108: 1, 128: 1, 79: 1, 103: 1, 90: 1, 85: 1, 81: 1, 84: 1, 101: 1, 124: 1, 97: 1, 116: 1, 120: 1, 104: 1, 118: 1, 111: 1, 98: 1, 115: 1, 73: 1, 109: 1, 106: 1, 122: 1, 114: 1, 112: 1, 107: 1, 119: 1, 117: 1, 123: 1, 125: 1, 22: 2, 29: 2, 25: 3, 18: 4, 15: 4, 28: 4, 19: 4, 13: 4, 9: 4, 20: 4, 12: 4, 10: 4, 11: 4, 17: 4, 21: 4, 14: 4, 16: 4, 24: 5, 26: 6, 27: 6, 23: 6}\n"
     ]
    }
   ],
   "source": [
    "# Load scRNAseq Dataset \n",
    "rdata = pyreadr.read_r(path)\n",
    "# Load data\n",
    "df = rdata['Retina_expMatrix_candidateGenes']\n",
    "df['Cluster'] = df['Cluster'].apply(lambda x: x if len(x.split('_')[0]) == 2 else '0' + x) # Standardize cluster names\n",
    "\n",
    "\n",
    "# Load the list of indices for each network to use\n",
    "class_net_genes = rdata['Class_indices'].to_numpy().ravel()\n",
    "rgc_net_genes = rdata['RGC_indices'].to_numpy().ravel()\n",
    "ac_net_genes = rdata['AC_indices'].to_numpy().ravel()\n",
    "bc_net_genes = rdata['BC_indices'].to_numpy().ravel()\n",
    "hc_net_genes = rdata['HC_indices'].to_numpy().ravel()\n",
    "nn_net_genes = rdata['NonNeural_indices'].to_numpy().ravel()\n",
    "\n",
    "# Encode and format scRNAseq dat\n",
    "df['cluster'] = df['Cluster']\n",
    "\n",
    "def encode_class(arr):\n",
    "    '''This function will encode subtypes' cell classesbased on expert rules and is not intended for decoding'''\n",
    "    custom_array = []\n",
    "\n",
    "    for value in arr:\n",
    "        if re.match(r'^\\d{2}_', value):\n",
    "            custom_array.append(0)\n",
    "        elif value.startswith('AC_'):\n",
    "            custom_array.append(1)\n",
    "        elif value.endswith('Photoreceptors'):\n",
    "            custom_array.append(2)\n",
    "        elif value == '0MG (Mueller Glia)':\n",
    "            custom_array.append(3)\n",
    "        elif value.startswith('0BC'):\n",
    "            custom_array.append(4)\n",
    "        elif value.startswith('0RBC'):\n",
    "            # Note this duplication is for simplicity of handling the 2 BC naming conventions\n",
    "            custom_array.append(4)\n",
    "        elif value == '0Horizontal Cell':\n",
    "            custom_array.append(5)\n",
    "        elif value == '0Pericyte':\n",
    "            custom_array.append(6)\n",
    "        elif value == '0Endothelial':\n",
    "            custom_array.append(6)\n",
    "        elif value == '0Microglia':\n",
    "            custom_array.append(6)   \n",
    "        else:\n",
    "            custom_array.append(7)\n",
    "    return custom_array\n",
    "\n",
    "# Function to generate a sort key for each subclass name\n",
    "def sort_key(name):\n",
    "    if name.startswith('0BC'):\n",
    "        return 4\n",
    "    elif name.startswith('0RBC'):\n",
    "        return 4\n",
    "    elif re.match(r'^\\d{2}_', name):\n",
    "        return 0\n",
    "    elif name.startswith('AC_'):\n",
    "        return 1\n",
    "    elif name.endswith('Photoreceptors'):\n",
    "        return 2\n",
    "    elif name == '0MG (Mueller Glia)':\n",
    "        return 3\n",
    "    elif name == '0Horizontal Cell':\n",
    "        return 5\n",
    "    elif name == '0Pericyte':\n",
    "        return 6\n",
    "    elif name == '0Endothelial':\n",
    "        return 6\n",
    "    elif name == '0Microglia':\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "# Apply the sort_key function to each subclass name and sort the DataFrame\n",
    "df['sort_key'] = df['Cluster'].apply(sort_key)\n",
    "df.sort_values(by='sort_key', inplace=True)\n",
    "df.drop(columns='sort_key', inplace=True)  # Optionally remove the sort key\n",
    "\n",
    "class_arr = encode_class(df['Cluster'])\n",
    "\n",
    "# Encode the categoric response \n",
    "le = LabelEncoder()\n",
    "df['Cluster'] = le.fit_transform(df['Cluster'])\n",
    "\n",
    "cluster_col = df.pop('Cluster')\n",
    "dataset_col = df.pop('Dataset')\n",
    "df.insert(len(df.columns), 'Cluster', cluster_col)\n",
    "df.insert(len(df.columns), 'Class', class_arr)\n",
    "\n",
    "display(df)\n",
    "\n",
    "def create_mapping(df):\n",
    "    # Extract the unique pairs of encoded cluster values and their corresponding class encodings\n",
    "    unique_pairs = df[['Cluster', 'Class']].drop_duplicates()\n",
    "    \n",
    "    # Create a dictionary mapping from Cluster to Class\n",
    "    mapping = dict(zip(unique_pairs['Cluster'], unique_pairs['Class']))\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "# Usage\n",
    "mapping = create_mapping(df)\n",
    "\n",
    "print(mapping)\n",
    "\n",
    "\n",
    "# Utilize the mapping to count the number of subclasses for each class\n",
    "subclass_counts = {i: 0 for i in range(8)}  # Initialize counts for 6 classes\n",
    "for _, class_id in mapping.items():\n",
    "    subclass_counts[class_id] += 1\n",
    "\n",
    "# Construct the class_info dictionary\n",
    "class_info = {\n",
    "    'Genes': class_net_genes,  # Genes used for class classification\n",
    "    'num_classes': 8,  # Total number of classes\n",
    "    0: {  # Information for class 0 (RGCs)\n",
    "        'Genes': rgc_net_genes,\n",
    "        'num_subclasses': subclass_counts[0]\n",
    "    },\n",
    "    1: {  # Information for class 1 (ACs)\n",
    "        'Genes': ac_net_genes,\n",
    "        'num_subclasses': subclass_counts[1]\n",
    "    },\n",
    "    2: {  # Information for class 2\n",
    "        'Genes': bc_net_genes,\n",
    "        'num_subclasses': subclass_counts[2]\n",
    "    },\n",
    "    3: {  # Information for class 3\n",
    "        'Genes': bc_net_genes,\n",
    "        'num_subclasses': subclass_counts[3]\n",
    "    },\n",
    "    4: {  # Information for class 4BC\n",
    "        'Genes': bc_net_genes,\n",
    "        'num_subclasses': subclass_counts[4]\n",
    "    },\n",
    "    5: {  # Information for class 5 HCs\n",
    "        'Genes': hc_net_genes,\n",
    "        'num_subclasses': subclass_counts[5]  \n",
    "    },\n",
    "    6: {  # Information for class 6 NonNeural\n",
    "        'Genes': nn_net_genes,\n",
    "        'num_subclasses': subclass_counts[6]  \n",
    "    },\n",
    "    7: {  # Information for class 5 (Catch-all class)\n",
    "        'Genes': class_net_genes,\n",
    "        'num_subclasses': 1  # Only 1 subclass as it's a catch-all class\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add 'num_hidden' with default zero to each tentacle\n",
    "for c in range(class_info['num_classes']):\n",
    "    class_info[c]['num_hidden'] = 0\n",
    "    class_info[c]['skip'] = False\n",
    "    \n",
    "\n",
    "l_arm = 5\n",
    "skip = True\n",
    "class_info[0]['num_hidden'] = l_arm # RGC Arm\n",
    "class_info[1]['num_hidden'] = l_arm # AC Arm\n",
    "class_info[0]['skip'] = skip # RGC Arm\n",
    "class_info[1]['skip'] = skip # AC Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9defa432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuttleNet(\n",
       "  (class_fc1): Linear(in_features=238, out_features=16, bias=True)\n",
       "  (class_fc2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (subclass_nets): ModuleDict(\n",
       "    (0): TentacleNet(\n",
       "      (fc1): Linear(in_features=278, out_features=90, bias=True)\n",
       "      (hidden): ModuleList(\n",
       "        (0-4): 5 x Linear(in_features=90, out_features=90, bias=True)\n",
       "      )\n",
       "      (fc2): Linear(in_features=90, out_features=45, bias=True)\n",
       "    )\n",
       "    (1): TentacleNet(\n",
       "      (fc1): Linear(in_features=284, out_features=126, bias=True)\n",
       "      (hidden): ModuleList(\n",
       "        (0-4): 5 x Linear(in_features=126, out_features=126, bias=True)\n",
       "      )\n",
       "      (fc2): Linear(in_features=126, out_features=63, bias=True)\n",
       "    )\n",
       "    (2): TentacleNet(\n",
       "      (fc1): Linear(in_features=233, out_features=4, bias=True)\n",
       "      (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
       "    )\n",
       "    (3): TentacleNet(\n",
       "      (fc1): Linear(in_features=233, out_features=2, bias=True)\n",
       "      (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    )\n",
       "    (4): TentacleNet(\n",
       "      (fc1): Linear(in_features=233, out_features=28, bias=True)\n",
       "      (fc2): Linear(in_features=28, out_features=14, bias=True)\n",
       "    )\n",
       "    (5): TentacleNet(\n",
       "      (fc1): Linear(in_features=10, out_features=2, bias=True)\n",
       "      (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    )\n",
       "    (6): TentacleNet(\n",
       "      (fc1): Linear(in_features=13, out_features=6, bias=True)\n",
       "      (fc2): Linear(in_features=6, out_features=3, bias=True)\n",
       "    )\n",
       "    (7): TentacleNet(\n",
       "      (fc1): Linear(in_features=246, out_features=2, bias=True)\n",
       "      (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TentacleNet(nn.Module):\n",
    "    def __init__(self, input_size, num_subclasses, num_hidden, skip = False):\n",
    "        super(TentacleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2*num_subclasses)\n",
    "        self.num_hidden = num_hidden\n",
    "        self.skip = skip+0\n",
    "        if self.num_hidden > 0:\n",
    "            self.hidden = nn.ModuleList([nn.Linear(2*num_subclasses, 2*num_subclasses) for _ in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(2*num_subclasses, num_subclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        if self.num_hidden > 0:\n",
    "            x_skip = x*self.skip  # Save output of fc1 for skip connection\n",
    "            for hidden_layer in self.hidden:\n",
    "                x = nn.functional.relu(hidden_layer(x))\n",
    "            x = x + x_skip  # Add skip connection before final activation\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class CuttleNet(nn.Module):\n",
    "    def __init__(self, class_info, mapping):\n",
    "        super(CuttleNet, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.n = len(mapping) # Number of subclasses\n",
    "        self.class_info = class_info\n",
    "\n",
    "        # Class Classifier\n",
    "        self.class_fc1 = nn.Linear(len(class_info['Genes']), 2*class_info['num_classes'])\n",
    "        self.class_fc2 = nn.Linear(2*class_info['num_classes'], class_info['num_classes'])\n",
    "\n",
    "        # Subclass Classifiers\n",
    "        self.subclass_nets = nn.ModuleDict({\n",
    "            str(class_id): TentacleNet(input_size=len(subclass_info['Genes']) + class_info['num_classes'], \n",
    "                                       num_subclasses=subclass_info['num_subclasses'],\n",
    "                                      num_hidden = subclass_info['num_hidden'],\n",
    "                                      skip = subclass_info['skip'])\n",
    "            for class_id, subclass_info in class_info.items()\n",
    "            if isinstance(class_id, int)\n",
    "        })\n",
    "        \n",
    "        # Calculate the number of subclasses for each class\n",
    "        self.num_subclasses_per_class = self.calculate_subclasses_per_class(mapping)\n",
    "        \n",
    "    def get_subclass_range_for_class(self, class_id):\n",
    "        start_index = sum(self.num_subclasses_per_class[cid] for cid in range(class_id))\n",
    "        end_index = start_index + self.num_subclasses_per_class[class_id]\n",
    "        return slice(start_index, end_index)\n",
    "    \n",
    "    def calculate_subclasses_per_class(self, mapping):\n",
    "        \"\"\"\n",
    "        Calculate the number of subclasses for each class using the mapping.\n",
    "        \"\"\"\n",
    "        num_subclasses_per_class = {class_id: 0 for class_id in range(self.class_info['num_classes'])}\n",
    "        for subclass_id in mapping.keys():\n",
    "            class_id = mapping[subclass_id]\n",
    "            num_subclasses_per_class[class_id] += 1\n",
    "        return num_subclasses_per_class\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Class classification\n",
    "        class_genes = x[:, self.class_info['Genes']]\n",
    "        class_x = nn.functional.relu(self.class_fc1(class_genes))\n",
    "        class_output = nn.functional.log_softmax(self.class_fc2(class_x), dim=1)\n",
    "\n",
    "        # Initialize an output tensor for all subclasses\n",
    "        all_subclass_output = torch.zeros(x.size(0), 130, device=self.device)  # Assuming 130 total subclasses\n",
    "\n",
    "        # Populate the output tensor\n",
    "        for class_id, subclass_info in self.class_info.items():\n",
    "            if isinstance(class_id, int):\n",
    "                subclass_genes = x[:, subclass_info['Genes']]\n",
    "                subclass_input = torch.cat((subclass_genes, class_output), dim=1)\n",
    "\n",
    "                # Convert class_id to string\n",
    "                class_id_str = str(class_id)\n",
    "                subclass_output = self.subclass_nets[class_id_str](subclass_input)\n",
    "\n",
    "                # Get the range for this class's subclasses\n",
    "                subclass_range = self.get_subclass_range_for_class(class_id)\n",
    "\n",
    "                # Multiply subclass predictions by the class prediction probability\n",
    "                all_subclass_output[:, subclass_range] = subclass_output * class_output[:, class_id].unsqueeze(1)\n",
    "\n",
    "        return all_subclass_output\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CuttleNet(class_info=class_info, mapping=mapping)\n",
    "\n",
    "# Load the model state\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Move the model to the appropriate device and set it to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce485929",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a9dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the slice\n",
    "df_slice = df.iloc[:, -3:-1]\n",
    "\n",
    "# Step 2: Drop the index\n",
    "df_slice_reset = df_slice.reset_index(drop=True)\n",
    "\n",
    "# Step 3: Remove duplicate rows\n",
    "df_unique = df_slice_reset.drop_duplicates()\n",
    "\n",
    "# Step 4: Sort by the last column (you can reference it by its position since it's a slice)\n",
    "df_sorted = df_unique.sort_values(by=df_unique.columns[-1])\n",
    "clust_ids = list(df_sorted[['cluster']].values.ravel())\n",
    "clust_ids.append('other')\n",
    "\n",
    "# Extract Correct gene order\n",
    "correct_order = np.array(df.iloc[:,0:-3].columns)\n",
    "# Correct any mislabeled genes\n",
    "gene_rename_map = {\n",
    "'Gm11744': 'Prcd',\n",
    "'Fam19a3': 'Tafa3',\n",
    "#     'A730046J19Rik': 'Sertm2',\n",
    "'Fam19a1': 'Tafa1',\n",
    "'Cyr61': 'Ccn1'\n",
    "}\n",
    "correct_order = np.array([gene_rename_map.get(gene, gene) for gene in correct_order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6621b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_matrix(df, correct_order):\n",
    "    # Pivot table to count occurrences of feature_name for each cell_id\n",
    "    count_matrix = pd.pivot_table(df, index='cell_id', columns='feature_name', aggfunc='size', fill_value=0)\n",
    "    count_matrix = count_matrix.loc[:,correct_order] # extract genes only\n",
    "    \n",
    "    return count_matrix\n",
    "\n",
    "def CuttleNet_Inference(data_root, clust_ids, correct_order,\n",
    "                        chunk_size = 10000):\n",
    "\n",
    "\n",
    "    print(f'Loading experiment data from {data_root}')\n",
    "    # load transcript data\n",
    "    data_path = os.path.join(data_root,\"transcripts.parquet\")\n",
    "\n",
    "    # Create an empty list to hold chunks\n",
    "    data_chunks = []\n",
    "    n_cells = 0\n",
    "    xen_data = pd.read_parquet(data_path,columns=['cell_id', 'feature_name'])\n",
    "\n",
    "    data = create_count_matrix(xen_data, correct_order)\n",
    "\n",
    "    # Remove the row with the index 'UNASSIGNED'\n",
    "    data = data.drop('UNASSIGNED')\n",
    "    # Normalize each column by its maximum value, multiply by 1000, round, and divide by 1000\n",
    "    data = data.apply(lambda x: round(1000 * x / x.max()) / 1000)\n",
    "    # store cell ids\n",
    "    cell_ids = list(data.index)\n",
    "\n",
    "    # Convert to torch tensor and store on GPU\n",
    "    expMatrix = data.to_numpy()\n",
    "    expMatrix = torch.tensor(expMatrix, dtype=torch.float32)\n",
    "\n",
    "    print(f'Data loaded containing {len(cell_ids)} cells')\n",
    "\n",
    "    # Calculate the number of chunks needed\n",
    "    n_chunks = int(np.ceil(expMatrix.size(0) / chunk_size))\n",
    "\n",
    "    # Placeholder to collect the output\n",
    "    results = []\n",
    "\n",
    "    print('Performing Inference')\n",
    "    # Process each chunk\n",
    "    for i in tqdm.tqdm(range(n_chunks)):\n",
    "        # Calculate the start and end indices of the current chunk\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = min((i + 1) * chunk_size, expMatrix.size(0))\n",
    "\n",
    "        # Extract the chunk\n",
    "        chunk = expMatrix[start_idx:end_idx]\n",
    "\n",
    "        # Move the chunk to GPU\n",
    "        chunk = chunk.to('cuda')\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():  # Ensure gradients are not computed to save memory\n",
    "            chunk_output = model(chunk)\n",
    "\n",
    "        # Move the results back to CPU and store them\n",
    "        chunk_output = chunk_output.cpu()\n",
    "        results.append(chunk_output)\n",
    "\n",
    "    # Concatenate the results into a single tensor\n",
    "    final_results = torch.cat(results, dim=0)\n",
    "\n",
    "    final_df = pd.DataFrame(final_results.numpy(), columns= clust_ids)\n",
    "    # Add Prediction column\n",
    "    final_df['Prediction'] = final_df.idxmax(axis=1)\n",
    "    # Add cell_ids column\n",
    "    final_df['cell_id'] = cell_ids\n",
    "\n",
    "    \n",
    "    # Load and store cell shape information    \n",
    "    print('Loading centroid information')\n",
    "#     cell_shape_path = os.path.join(data_root,\"cell_boundaries.csv.gz\")\n",
    "#     nuc_shape_path = os.path.join(data_root,\"nucleus_boundaries.csv.gz\")\n",
    "    cent_shape_path = os.path.join(data_root,\"cells.parquet\")\n",
    "\n",
    "#     cell_shape_data = pd.read_csv(cell_shape_path, compression='gzip') # load data\n",
    "#     cell_shape_data = cell_shape_data.add_suffix('_cell') # add specific suffix to columns\n",
    "#     cell_shape_data = cell_shape_data.rename(index=str, columns={'cell_id_cell':'cell_id'}) # Rename cell_id\n",
    "#     nuc_shape_data = pd.read_csv(nuc_shape_path, compression='gzip') # load data\n",
    "#     nuc_shape_data = nuc_shape_data.add_suffix('_nucleus') # add specific suffix to columns\n",
    "#     nuc_shape_data = nuc_shape_data.rename(index=str, columns={'cell_id_nucleus':'cell_id'}) # Rename cell_id\n",
    "#     bounds_shape_data = cell_shape_data.merge(nuc_shape_data, on='cell_id') # merge data\n",
    "    cent_shape_data = pd.read_parquet(cent_shape_path, columns=['cell_id', 'x_centroid', 'y_centroid']) # load data\n",
    "    final_df = final_df.merge(cent_shape_data, on='cell_id') # merge data\n",
    "#     bounds_shape_data = bounds_shape_data.merge(cent_shape_data, on='cell_id') # merge data\n",
    "    \n",
    "#     final_df = final_df.merge(bounds_shape_data, on='cell_id') # merge data\n",
    "    \n",
    "    print('Inference and dataframe merging complete.')\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8434e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/output-XETG00230__0018429__Region_1__20240105__233208\n",
      "Data loaded containing 791635 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 80/80 [00:00<00:00, 171.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/output-XETG00230__0018432__Region_2__20240105__233208\n",
      "Data loaded containing 101846 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 11/11 [00:00<00:00, 159.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun2_Slide 3_4/BudoffRun2_Slide 3_4/output-XETG00230__0018336__Region_1__20240124__002923\n",
      "Data loaded containing 336896 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 34/34 [00:00<00:00, 166.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun2_Slide 3_4/BudoffRun2_Slide 3_4/output-XETG00230__0018521__Region_1__20240124__002923\n",
      "Data loaded containing 471721 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 48/48 [00:00<00:00, 177.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun3_Slide 5_6/BudoffRun3_Slide 5_6/output-XETG00230__0018624__Region_1__20240127__000149\n",
      "Data loaded containing 281791 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 29/29 [00:00<00:00, 154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun3_Slide 5_6/BudoffRun3_Slide 5_6/output-XETG00230__0022826__Region_1__20240127__000149\n",
      "Data loaded containing 491503 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 50/50 [00:00<00:00, 175.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun4_Slide 7_8/BudoffRun4_Slide 7_8/output-XETG00230__0018300__Region_1__20240206__235339\n",
      "Data loaded containing 247413 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 25/25 [00:00<00:00, 130.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n",
      "Loading experiment data from /media/sam/New Volume/Xenium_Data/BudoffRun4_Slide 7_8/BudoffRun4_Slide 7_8/output-XETG00230__0022825__Region_1__20240206__235339\n",
      "Data loaded containing 395189 cells\n",
      "Performing Inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 40/40 [00:00<00:00, 140.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centroid information\n",
      "Inference and dataframe merging complete.\n",
      "Saving full dataframe\n"
     ]
    }
   ],
   "source": [
    "experiments = {0 : {'slide' : '0018429',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/output-XETG00230__0018429__Region_1__20240105__233208'},\n",
    "               1 : {'slide' : '0018432',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/output-XETG00230__0018432__Region_2__20240105__233208'},\n",
    "               2 : {'slide' : '0018336',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun2_Slide 3_4/BudoffRun2_Slide 3_4/output-XETG00230__0018336__Region_1__20240124__002923'},\n",
    "               3 : {'slide' : '0018521',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun2_Slide 3_4/BudoffRun2_Slide 3_4/output-XETG00230__0018521__Region_1__20240124__002923'},\n",
    "               4 : {'slide' : '0018624',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun3_Slide 5_6/BudoffRun3_Slide 5_6/output-XETG00230__0018624__Region_1__20240127__000149'},\n",
    "               5 : {'slide' : '0022826',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun3_Slide 5_6/BudoffRun3_Slide 5_6/output-XETG00230__0022826__Region_1__20240127__000149'},\n",
    "               6 : {'slide' : '0018300',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun4_Slide 7_8/BudoffRun4_Slide 7_8/output-XETG00230__0018300__Region_1__20240206__235339'},\n",
    "               7 : {'slide' : '0022825',\n",
    "                   'path' : '/media/sam/New Volume/Xenium_Data/BudoffRun4_Slide 7_8/BudoffRun4_Slide 7_8/output-XETG00230__0022825__Region_1__20240206__235339'}}\n",
    "\n",
    "save_path = '/home/sam/scRNAseq/Xenium/Full_Inference_All_Experiments.csv'\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    data_root = experiments[i]['path']\n",
    "    inf_df = CuttleNet_Inference(data_root, clust_ids, correct_order)\n",
    "    inf_df['slide'] = experiments[i]['slide']\n",
    "    if i == 0:\n",
    "        full_df = inf_df.copy()\n",
    "    else:\n",
    "        full_df = pd.concat((full_df, inf_df))\n",
    "    \n",
    "    print('Saving full dataframe')\n",
    "    full_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6728818e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>01_W3D1.1</th>\n",
       "      <th>02_W3D1.2</th>\n",
       "      <th>03_FminiON</th>\n",
       "      <th>04_FminiOFF</th>\n",
       "      <th>05_J-RGC</th>\n",
       "      <th>06_W3B</th>\n",
       "      <th>07_Novel</th>\n",
       "      <th>08_Novel</th>\n",
       "      <th>09_Tbr1_Novel</th>\n",
       "      <th>...</th>\n",
       "      <th>AC_63</th>\n",
       "      <th>AC_7</th>\n",
       "      <th>AC_8</th>\n",
       "      <th>AC_9</th>\n",
       "      <th>other</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>x_centroid</th>\n",
       "      <th>y_centroid</th>\n",
       "      <th>slide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.499385</td>\n",
       "      <td>13.473839</td>\n",
       "      <td>11.815074</td>\n",
       "      <td>11.647055</td>\n",
       "      <td>12.683795</td>\n",
       "      <td>12.163663</td>\n",
       "      <td>11.894971</td>\n",
       "      <td>11.693455</td>\n",
       "      <td>12.508800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>13.855881</td>\n",
       "      <td>10.719368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AC_57</td>\n",
       "      <td>aaaaaefg-1</td>\n",
       "      <td>1504.220093</td>\n",
       "      <td>3392.329834</td>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.840160</td>\n",
       "      <td>19.547691</td>\n",
       "      <td>16.483750</td>\n",
       "      <td>14.670475</td>\n",
       "      <td>20.701984</td>\n",
       "      <td>17.944050</td>\n",
       "      <td>18.400510</td>\n",
       "      <td>17.254879</td>\n",
       "      <td>17.839075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>26.022734</td>\n",
       "      <td>32.609207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AC_13</td>\n",
       "      <td>aaaaagcc-1</td>\n",
       "      <td>1505.094360</td>\n",
       "      <td>3399.590088</td>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.139815</td>\n",
       "      <td>3.592308</td>\n",
       "      <td>3.998503</td>\n",
       "      <td>2.680553</td>\n",
       "      <td>3.384927</td>\n",
       "      <td>3.572677</td>\n",
       "      <td>3.027277</td>\n",
       "      <td>2.990842</td>\n",
       "      <td>3.229471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>6.313530</td>\n",
       "      <td>8.020874</td>\n",
       "      <td>0.846739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AC_41</td>\n",
       "      <td>aaaaefcg-1</td>\n",
       "      <td>1505.547241</td>\n",
       "      <td>3376.981689</td>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.000996</td>\n",
       "      <td>4.225929</td>\n",
       "      <td>3.773240</td>\n",
       "      <td>2.983864</td>\n",
       "      <td>4.478297</td>\n",
       "      <td>3.990880</td>\n",
       "      <td>3.843720</td>\n",
       "      <td>3.945924</td>\n",
       "      <td>4.336253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>18.441433</td>\n",
       "      <td>18.661541</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AC_1</td>\n",
       "      <td>aaaaejab-1</td>\n",
       "      <td>1505.079346</td>\n",
       "      <td>3385.811768</td>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.722825</td>\n",
       "      <td>7.136056</td>\n",
       "      <td>7.496596</td>\n",
       "      <td>5.754329</td>\n",
       "      <td>8.066427</td>\n",
       "      <td>8.525160</td>\n",
       "      <td>6.790527</td>\n",
       "      <td>7.223733</td>\n",
       "      <td>8.755570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>6.728914</td>\n",
       "      <td>8.212195</td>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AC_27</td>\n",
       "      <td>aaaaenmn-1</td>\n",
       "      <td>1510.195923</td>\n",
       "      <td>3383.330566</td>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  01_W3D1.1  02_W3D1.2  03_FminiON  04_FminiOFF   05_J-RGC  \\\n",
       "0           0  13.499385  13.473839   11.815074    11.647055  12.683795   \n",
       "1           1  20.840160  19.547691   16.483750    14.670475  20.701984   \n",
       "2           2   4.139815   3.592308    3.998503     2.680553   3.384927   \n",
       "3           3   5.000996   4.225929    3.773240     2.983864   4.478297   \n",
       "4           4   8.722825   7.136056    7.496596     5.754329   8.066427   \n",
       "\n",
       "      06_W3B   07_Novel   08_Novel  09_Tbr1_Novel  ...  AC_63       AC_7  \\\n",
       "0  12.163663  11.894971  11.693455      12.508800  ...   -0.0   0.377131   \n",
       "1  17.944050  18.400510  17.254879      17.839075  ...   -0.0   0.006681   \n",
       "2   3.572677   3.027277   2.990842       3.229471  ...   -0.0   6.313530   \n",
       "3   3.990880   3.843720   3.945924       4.336253  ...   -0.0  18.441433   \n",
       "4   8.525160   6.790527   7.223733       8.755570  ...   -0.0   6.728914   \n",
       "\n",
       "        AC_8       AC_9  other  Prediction     cell_id   x_centroid  \\\n",
       "0  13.855881  10.719368    0.0       AC_57  aaaaaefg-1  1504.220093   \n",
       "1  26.022734  32.609207    0.0       AC_13  aaaaagcc-1  1505.094360   \n",
       "2   8.020874   0.846739    0.0       AC_41  aaaaefcg-1  1505.547241   \n",
       "3  18.661541   0.078183    0.0        AC_1  aaaaejab-1  1505.079346   \n",
       "4   8.212195   0.579094    0.0       AC_27  aaaaenmn-1  1510.195923   \n",
       "\n",
       "    y_centroid  slide  \n",
       "0  3392.329834  18429  \n",
       "1  3399.590088  18429  \n",
       "2  3376.981689  18429  \n",
       "3  3385.811768  18429  \n",
       "4  3383.330566  18429  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv(save_path)\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deccffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3117994\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56c25239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117994"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "395189+247413+491503+281791+471721+336896+101846+791635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "573e4e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "01_W3D1.1\n",
      "02_W3D1.2\n",
      "03_FminiON\n",
      "04_FminiOFF\n",
      "05_J-RGC\n",
      "06_W3B\n",
      "07_Novel\n",
      "08_Novel\n",
      "09_Tbr1_Novel\n",
      "0BC1A\n",
      "0BC1B\n",
      "0BC2\n",
      "0BC3A\n",
      "0BC3B\n",
      "0BC4\n",
      "0BC5A (Cone Bipolar cell 5A)\n",
      "0BC5B\n",
      "0BC5C\n",
      "0BC5D\n",
      "0BC6\n",
      "0BC7 (Cone Bipolar cell 7)\n",
      "0BC8/9 (mixture of BC8 and BC9)\n",
      "0Cone Photoreceptors\n",
      "0Endothelial\n",
      "0Horizontal Cell\n",
      "0MG (Mueller Glia)\n",
      "0Microglia\n",
      "0Pericyte\n",
      "0RBC (Rod Bipolar cell)\n",
      "0Rod Photoreceptors\n",
      "10_Novel\n",
      "11_Novel\n",
      "12_ooDS_NT\n",
      "13_Novel\n",
      "14_ooDS_Cck\n",
      "15_Novel\n",
      "16_ooDS_DV\n",
      "17_Tbr1_S1\n",
      "18_Novel\n",
      "19_Novel\n",
      "20_Novel\n",
      "21_Tbr1_S2\n",
      "22_M5\n",
      "23_W3D2\n",
      "24_Novel\n",
      "25_Novel\n",
      "26_Novel\n",
      "27_Novel\n",
      "28_FmidiOFF\n",
      "29_Novel\n",
      "30_Novel\n",
      "31_M2\n",
      "32_F_Novel\n",
      "33_M1\n",
      "34_Novel\n",
      "35_Novel\n",
      "36_Novel\n",
      "37_Novel\n",
      "38_FmidiON\n",
      "39_Novel\n",
      "40_M1dup\n",
      "41_AlphaONT\n",
      "42_AlphaOFFS\n",
      "43_AlphaONS\n",
      "44_Novel\n",
      "45_AlphaOFFT\n",
      "AC_1\n",
      "AC_10\n",
      "AC_11\n",
      "AC_12\n",
      "AC_13\n",
      "AC_14\n",
      "AC_15\n",
      "AC_16\n",
      "AC_17\n",
      "AC_18\n",
      "AC_19\n",
      "AC_2\n",
      "AC_20\n",
      "AC_21\n",
      "AC_22\n",
      "AC_23\n",
      "AC_24\n",
      "AC_25\n",
      "AC_26\n",
      "AC_27\n",
      "AC_28\n",
      "AC_29\n",
      "AC_3\n",
      "AC_30\n",
      "AC_31\n",
      "AC_32\n",
      "AC_33\n",
      "AC_34\n",
      "AC_35\n",
      "AC_36\n",
      "AC_37\n",
      "AC_38\n",
      "AC_39\n",
      "AC_4\n",
      "AC_40\n",
      "AC_41\n",
      "AC_42\n",
      "AC_43\n",
      "AC_44\n",
      "AC_45\n",
      "AC_46\n",
      "AC_47\n",
      "AC_48\n",
      "AC_49\n",
      "AC_5\n",
      "AC_50\n",
      "AC_51\n",
      "AC_52\n",
      "AC_53\n",
      "AC_54\n",
      "AC_55\n",
      "AC_56\n",
      "AC_57\n",
      "AC_58\n",
      "AC_59\n",
      "AC_6\n",
      "AC_60\n",
      "AC_61\n",
      "AC_62\n",
      "AC_63\n",
      "AC_7\n",
      "AC_8\n",
      "AC_9\n",
      "other\n",
      "Prediction\n",
      "cell_id\n",
      "x_centroid\n",
      "y_centroid\n",
      "slide\n"
     ]
    }
   ],
   "source": [
    "for c in test.columns:\n",
    "    print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
